{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48e11bf677c449caaa26f3443184eee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27ee2d2702f0499a96ef9899022ffde7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_341bdb6258ff48b1befeb96fdf2cd2b5",
              "IPY_MODEL_32e256776be74efe8c8cc3d628f319bd"
            ]
          }
        },
        "27ee2d2702f0499a96ef9899022ffde7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "341bdb6258ff48b1befeb96fdf2cd2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ebeb9d7679b44d59d13fd2dfc89e5a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81798ff972094589b9c3dceb74fee2e7"
          }
        },
        "32e256776be74efe8c8cc3d628f319bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_260a3a2f7a50439ea97c621d0f6342dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:30, 15519228.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fab69c18bd644415bfcde70ada752c86"
          }
        },
        "1ebeb9d7679b44d59d13fd2dfc89e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81798ff972094589b9c3dceb74fee2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "260a3a2f7a50439ea97c621d0f6342dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fab69c18bd644415bfcde70ada752c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NEl50YpzoF8R",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WaUoLVcroF8W"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make\n",
        "updates to the weights of the network.\n",
        "\n",
        "Now you might be thinking,\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: â€˜airplaneâ€™, â€˜automobileâ€™, â€˜birdâ€™, â€˜catâ€™, â€˜deerâ€™,\n",
        "â€˜dogâ€™, â€˜frogâ€™, â€˜horseâ€™, â€˜shipâ€™, â€˜truckâ€™. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        ".. figure:: /_static/img/cifar10.png\n",
        "   :alt: cifar10\n",
        "\n",
        "   cifar10\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Loading and normalizing CIFAR10\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Using ``torchvision``, itâ€™s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjWzKeezoF8X",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uOqWQOZ4oF8c"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LSZHtJv-oF8e",
        "outputId": "d5d8c473-82ad-446e-fb63-ac2a0080ba1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "48e11bf677c449caaa26f3443184eee7",
            "27ee2d2702f0499a96ef9899022ffde7",
            "341bdb6258ff48b1befeb96fdf2cd2b5",
            "32e256776be74efe8c8cc3d628f319bd",
            "1ebeb9d7679b44d59d13fd2dfc89e5a9",
            "81798ff972094589b9c3dceb74fee2e7",
            "260a3a2f7a50439ea97c621d0f6342dc",
            "fab69c18bd644415bfcde70ada752c86"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e11bf677c449caaa26f3443184eee7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O-eP8xF3oF8h"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HGYX3kCIoF8i",
        "outputId": "42ed2d84-6486-4655-c7c7-c1501b810297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  cat horse  bird horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SJWpMjxloF8l"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b2DBhMJooF8m",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FsdFeoAVoF8p"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FegiYpJYoF8q",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OB9AN67YoF8t"
      },
      "source": [
        "4. Train the network\n",
        "^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cMWVgPkdoF8v",
        "outputId": "8227d441-73b1-43cf-aed6-0446349dd30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.169\n",
            "[1,  4000] loss: 1.793\n",
            "[1,  6000] loss: 1.661\n",
            "[1,  8000] loss: 1.575\n",
            "[1, 10000] loss: 1.515\n",
            "[1, 12000] loss: 1.472\n",
            "[2,  2000] loss: 1.388\n",
            "[2,  4000] loss: 1.368\n",
            "[2,  6000] loss: 1.331\n",
            "[2,  8000] loss: 1.294\n",
            "[2, 10000] loss: 1.284\n",
            "[2, 12000] loss: 1.263\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZP8yrd6qoF8z"
      },
      "source": [
        "5. Test the network on the test data\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UFrj02UBoF80",
        "outputId": "a7e40526-d068-47a5-8fc3-f99bc3d4da5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxf8HV/T+BepgTjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M8kENRSgoF84"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XliNvZygoF85",
        "colab": {}
      },
      "source": [
        "outputs = net(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jTF74biYoF88"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "Higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "py62U3kZoF89",
        "outputId": "843d3e6f-8a84-4fbf-8a50-a965f30124be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:    cat  ship   car plane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OEUrzYaioF9C"
      },
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O8OKMCt8oF9D",
        "outputId": "32b343f0-f2af-41f2-b9f6-4056c69fbf07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 53 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3kIoRQu9oF9I"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kSYfF9VmoF9J",
        "outputId": "c4fe598d-1435-4419-9779-1214f670fa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 70 %\n",
            "Accuracy of   car : 74 %\n",
            "Accuracy of  bird : 52 %\n",
            "Accuracy of   cat : 50 %\n",
            "Accuracy of  deer : 45 %\n",
            "Accuracy of   dog : 15 %\n",
            "Accuracy of  frog : 63 %\n",
            "Accuracy of horse : 51 %\n",
            "Accuracy of  ship : 62 %\n",
            "Accuracy of truck : 53 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C7YFb9fyoF9N"
      },
      "source": [
        "Okay, so what next?\n",
        "\n",
        "How do we run these neural networks on the GPU?\n",
        "\n",
        "Training on GPU\n",
        "----------------\n",
        "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
        "net onto the GPU.\n",
        "\n",
        "Let's first define our device as the first visible cuda device if we have\n",
        "CUDA available:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QdobZzlxoF9N",
        "outputId": "1e771a1b-a58c-4dfa-9076-f5287552022c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lceHMDU4oF9R"
      },
      "source": [
        "The rest of this section assumes that `device` is a CUDA device.\n",
        "\n",
        "Then these methods will recursively go over all modules and convert their\n",
        "parameters and buffers to CUDA tensors:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step\n",
        "to the GPU too:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is realllly small.\n",
        "\n",
        "**Exercise:** Try increasing the width of your network (argument 2 of\n",
        "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` â€“\n",
        "they need to be the same number), see what kind of speedup you get.\n",
        "\n",
        "**Goals achieved**:\n",
        "\n",
        "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
        "- Train a small neural network to classify images\n",
        "\n",
        "PRACTICUM TASK\n",
        "-------------------------\n",
        "\n",
        "1 - For recently trained model calculate accuracy, precision, recall, f1-score and print it. Construct confusion matrix.\n",
        "\n",
        "2 - Modify network below (Better_net) and training process, to achieve 90% accuracy on CIFAR10 dataset (higher is better)\n",
        "\n",
        "3 - Evaluate resulting model (calculate metrics from question 1)\n",
        "\n",
        "4* - OPTIONAL, perform training on the CPU and on the GPU, compare calculation time. Print it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txBIf6lh5OTZ",
        "colab_type": "text"
      },
      "source": [
        "Better net class (need to be modified)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zhCLjElcp2sk",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import copy\n",
        "class Better_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Better_net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bnm1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 160, 3, padding=1)\n",
        "        self.bnm2 = nn.BatchNorm2d(160)\n",
        "        self.conv3 = nn.Conv2d(160, 800, 3, padding=1)\n",
        "        self.bnm3 = nn.BatchNorm2d(800)\n",
        "        self.conv4 = nn.Conv2d(800, 3600, 3)\n",
        "        self.bnm4 = nn.BatchNorm2d(3600)\n",
        "        self.conv5 = nn.Conv2d(3600, 3600, 3, padding=1)\n",
        "        self.bnm5 = nn.BatchNorm2d(3600)\n",
        "        self.fc1 = nn.Linear(3*3*3600, 6000)\n",
        "        self.fc2 = nn.Linear(6000, 620)\n",
        "        self.fc3 = nn.Linear(620, 86)\n",
        "        self.fc4 = nn.Linear(86, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.bnm2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.bnm4(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.bnm5(x)\n",
        "        x = x.view(-1, 3*3*3600)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "net = Better_net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2AoOC1Z5OTe",
        "colab_type": "text"
      },
      "source": [
        "Optimizer (can be changed, tuned)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn3Ru39U5OTg",
        "colab_type": "code",
        "outputId": "624e1b9d-2b05-4db9-e49f-d5285bbd93fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr=0.01\n",
        "momentum = 0.4\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Better_net().to(device)\n",
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better_net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(160, 800, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm3): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(800, 3600, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bnm4): BatchNorm2d(3600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(3600, 3600, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bnm5): BatchNorm2d(3600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=32400, out_features=6000, bias=True)\n",
            "  (fc2): Linear(in_features=6000, out_features=620, bias=True)\n",
            "  (fc3): Linear(in_features=620, out_features=86, bias=True)\n",
            "  (fc4): Linear(in_features=86, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwp_sGaP6gej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, trainloader, optimizer, epoch,log_interval):\n",
        "    model.train()\n",
        "    avg_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # zero the gradient buffers\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step() # Does the update\n",
        "        avg_loss+=F.nll_loss(output, target, reduction='sum').item()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} [{:5.0f}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(trainloader.dataset),\n",
        "              100. * batch_idx / len(trainloader), loss.item()))\n",
        "    avg_loss/=len(trainloader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, device, testloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in testloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(testloader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
        "        test_loss, correct, len(testloader.dataset),\n",
        "        100. * correct / len(testloader.dataset)))\n",
        "    accuracy = 100. * correct / len(testloader.dataset)\n",
        "    print(\"Best Accuracy  \", best_acc)\n",
        "    accuracy = 100. * correct / len(testloader.dataset)\n",
        "    return test_loss,accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMbC2U4A5OTj",
        "colab_type": "text"
      },
      "source": [
        "Model training (need to be modified)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqhpXiWq5OTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5\n",
        "log_interval = 500\n",
        "save_model = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcMyJSy05OTp",
        "colab_type": "text"
      },
      "source": [
        "Model evaluation code must be written below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdGVf46V5OTr",
        "colab_type": "code",
        "outputId": "54a24e59-9728-4fe2-9634-ad855cf22fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "accuracy_list = []\n",
        "optimizer = optim.SGD(model.parameters(), lr, momentum=momentum)\n",
        "best_acc = 0.0\n",
        "best_model_wts = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    trn_loss = train(model, device, trainloader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, testloader)\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "    if epoch%9 == 0:\n",
        "        lr = lr*0.7\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "        torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")\n",
        "\n",
        "torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [    0/50000 (0%)]\tLoss: 1.346950\n",
            "Train Epoch: 1 [ 2000/50000 (4%)]\tLoss: 0.872217\n",
            "Train Epoch: 1 [ 4000/50000 (8%)]\tLoss: 1.434881\n",
            "Train Epoch: 1 [ 6000/50000 (12%)]\tLoss: 1.848572\n",
            "Train Epoch: 1 [ 8000/50000 (16%)]\tLoss: 2.399474\n",
            "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 1.367857\n",
            "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 0.615972\n",
            "Train Epoch: 1 [14000/50000 (28%)]\tLoss: 1.303334\n",
            "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.617450\n",
            "Train Epoch: 1 [18000/50000 (36%)]\tLoss: 1.484095\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1.341029\n",
            "Train Epoch: 1 [22000/50000 (44%)]\tLoss: 1.189057\n",
            "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 1.437100\n",
            "Train Epoch: 1 [26000/50000 (52%)]\tLoss: 0.671675\n",
            "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 2.430230\n",
            "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 0.421243\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.139395\n",
            "Train Epoch: 1 [34000/50000 (68%)]\tLoss: 0.676346\n",
            "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 0.570625\n",
            "Train Epoch: 1 [38000/50000 (76%)]\tLoss: 0.997390\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.819640\n",
            "Train Epoch: 1 [42000/50000 (84%)]\tLoss: 0.947385\n",
            "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 1.341985\n",
            "Train Epoch: 1 [46000/50000 (92%)]\tLoss: 0.963313\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.353382\n",
            "\n",
            "Test set: Average loss: 0.9993, Accuracy: 6678/10000 (66.8%)\n",
            "\n",
            "Best Accuracy   0.0\n",
            "Train Epoch: 2 [    0/50000 (0%)]\tLoss: 0.635860\n",
            "Train Epoch: 2 [ 2000/50000 (4%)]\tLoss: 0.553372\n",
            "Train Epoch: 2 [ 4000/50000 (8%)]\tLoss: 0.577968\n",
            "Train Epoch: 2 [ 6000/50000 (12%)]\tLoss: 0.172353\n",
            "Train Epoch: 2 [ 8000/50000 (16%)]\tLoss: 0.944976\n",
            "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 2.068895\n",
            "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 0.108944\n",
            "Train Epoch: 2 [14000/50000 (28%)]\tLoss: 2.250365\n",
            "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.762016\n",
            "Train Epoch: 2 [18000/50000 (36%)]\tLoss: 0.987075\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 0.544396\n",
            "Train Epoch: 2 [22000/50000 (44%)]\tLoss: 0.153790\n",
            "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.030280\n",
            "Train Epoch: 2 [26000/50000 (52%)]\tLoss: 1.150993\n",
            "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 0.287551\n",
            "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 0.392144\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.972706\n",
            "Train Epoch: 2 [34000/50000 (68%)]\tLoss: 1.447201\n",
            "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 1.738949\n",
            "Train Epoch: 2 [38000/50000 (76%)]\tLoss: 0.973430\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.407203\n",
            "Train Epoch: 2 [42000/50000 (84%)]\tLoss: 1.056624\n",
            "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 1.007982\n",
            "Train Epoch: 2 [46000/50000 (92%)]\tLoss: 0.574822\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.890994\n",
            "\n",
            "Test set: Average loss: 0.7885, Accuracy: 7408/10000 (74.1%)\n",
            "\n",
            "Best Accuracy   66.78\n",
            "Train Epoch: 3 [    0/50000 (0%)]\tLoss: 0.372896\n",
            "Train Epoch: 3 [ 2000/50000 (4%)]\tLoss: 0.246888\n",
            "Train Epoch: 3 [ 4000/50000 (8%)]\tLoss: 0.663044\n",
            "Train Epoch: 3 [ 6000/50000 (12%)]\tLoss: 0.492724\n",
            "Train Epoch: 3 [ 8000/50000 (16%)]\tLoss: 0.498533\n",
            "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 0.200000\n",
            "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 0.367458\n",
            "Train Epoch: 3 [14000/50000 (28%)]\tLoss: 0.017550\n",
            "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.270661\n",
            "Train Epoch: 3 [18000/50000 (36%)]\tLoss: 0.290133\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1.774813\n",
            "Train Epoch: 3 [22000/50000 (44%)]\tLoss: 0.522026\n",
            "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.034119\n",
            "Train Epoch: 3 [26000/50000 (52%)]\tLoss: 0.630867\n",
            "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 0.901617\n",
            "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 0.121616\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 2.011195\n",
            "Train Epoch: 3 [34000/50000 (68%)]\tLoss: 1.354310\n",
            "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 2.116921\n",
            "Train Epoch: 3 [38000/50000 (76%)]\tLoss: 0.546510\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 2.512852\n",
            "Train Epoch: 3 [42000/50000 (84%)]\tLoss: 0.110965\n",
            "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 0.405862\n",
            "Train Epoch: 3 [46000/50000 (92%)]\tLoss: 0.242517\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.208809\n",
            "\n",
            "Test set: Average loss: 0.7139, Accuracy: 7710/10000 (77.1%)\n",
            "\n",
            "Best Accuracy   74.08\n",
            "Train Epoch: 4 [    0/50000 (0%)]\tLoss: 0.833230\n",
            "Train Epoch: 4 [ 2000/50000 (4%)]\tLoss: 0.531822\n",
            "Train Epoch: 4 [ 4000/50000 (8%)]\tLoss: 0.614573\n",
            "Train Epoch: 4 [ 6000/50000 (12%)]\tLoss: 0.264366\n",
            "Train Epoch: 4 [ 8000/50000 (16%)]\tLoss: 0.184866\n",
            "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.680121\n",
            "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 0.544201\n",
            "Train Epoch: 4 [14000/50000 (28%)]\tLoss: 2.245872\n",
            "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.360111\n",
            "Train Epoch: 4 [18000/50000 (36%)]\tLoss: 0.819843\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.838377\n",
            "Train Epoch: 4 [22000/50000 (44%)]\tLoss: 0.776150\n",
            "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 0.000176\n",
            "Train Epoch: 4 [26000/50000 (52%)]\tLoss: 0.289883\n",
            "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 0.538161\n",
            "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 0.184159\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.161194\n",
            "Train Epoch: 4 [34000/50000 (68%)]\tLoss: 0.002514\n",
            "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 0.184671\n",
            "Train Epoch: 4 [38000/50000 (76%)]\tLoss: 0.596308\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1.752156\n",
            "Train Epoch: 4 [42000/50000 (84%)]\tLoss: 0.381747\n",
            "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 0.001984\n",
            "Train Epoch: 4 [46000/50000 (92%)]\tLoss: 0.616261\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.370240\n",
            "\n",
            "Test set: Average loss: 0.6703, Accuracy: 7898/10000 (79.0%)\n",
            "\n",
            "Best Accuracy   77.1\n",
            "Train Epoch: 5 [    0/50000 (0%)]\tLoss: 0.023096\n",
            "Train Epoch: 5 [ 2000/50000 (4%)]\tLoss: 0.026004\n",
            "Train Epoch: 5 [ 4000/50000 (8%)]\tLoss: 0.156658\n",
            "Train Epoch: 5 [ 6000/50000 (12%)]\tLoss: 0.072548\n",
            "Train Epoch: 5 [ 8000/50000 (16%)]\tLoss: 0.003831\n",
            "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 0.959311\n",
            "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 0.070443\n",
            "Train Epoch: 5 [14000/50000 (28%)]\tLoss: 0.739384\n",
            "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.139622\n",
            "Train Epoch: 5 [18000/50000 (36%)]\tLoss: 0.153516\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1.031785\n",
            "Train Epoch: 5 [22000/50000 (44%)]\tLoss: 0.180301\n",
            "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 0.078660\n",
            "Train Epoch: 5 [26000/50000 (52%)]\tLoss: 0.163228\n",
            "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 0.198171\n",
            "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 0.114777\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.313947\n",
            "Train Epoch: 5 [34000/50000 (68%)]\tLoss: 0.015219\n",
            "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 0.076264\n",
            "Train Epoch: 5 [38000/50000 (76%)]\tLoss: 0.027768\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.200038\n",
            "Train Epoch: 5 [42000/50000 (84%)]\tLoss: 0.872725\n",
            "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 0.044432\n",
            "Train Epoch: 5 [46000/50000 (92%)]\tLoss: 0.031743\n",
            "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.085723\n",
            "\n",
            "Test set: Average loss: 0.7179, Accuracy: 7863/10000 (78.6%)\n",
            "\n",
            "Best Accuracy   78.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37i7GzP5Zw1i",
        "colab_type": "code",
        "outputId": "b4b38c0e-cd0e-483d-c590-19a6bfba3a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(6, 10):\n",
        "    trn_loss = train(model, device, trainloader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, testloader)\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "    if epoch%3 == 0:\n",
        "        lr = lr*0.9\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "        torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")\n",
        "\n",
        "torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 6 [    0/50000 (0%)]\tLoss: 0.094972\n",
            "Train Epoch: 6 [ 2000/50000 (4%)]\tLoss: 0.260561\n",
            "Train Epoch: 6 [ 4000/50000 (8%)]\tLoss: 0.000674\n",
            "Train Epoch: 6 [ 6000/50000 (12%)]\tLoss: 0.037289\n",
            "Train Epoch: 6 [ 8000/50000 (16%)]\tLoss: 0.062203\n",
            "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 0.832390\n",
            "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 0.758639\n",
            "Train Epoch: 6 [14000/50000 (28%)]\tLoss: 0.279592\n",
            "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 1.289194\n",
            "Train Epoch: 6 [18000/50000 (36%)]\tLoss: 0.000629\n",
            "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.024157\n",
            "Train Epoch: 6 [22000/50000 (44%)]\tLoss: 0.000070\n",
            "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 0.368517\n",
            "Train Epoch: 6 [26000/50000 (52%)]\tLoss: 0.301950\n",
            "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 0.168063\n",
            "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 0.310741\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.053508\n",
            "Train Epoch: 6 [34000/50000 (68%)]\tLoss: 0.205563\n",
            "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 0.200315\n",
            "Train Epoch: 6 [38000/50000 (76%)]\tLoss: 0.184816\n",
            "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 0.083845\n",
            "Train Epoch: 6 [42000/50000 (84%)]\tLoss: 0.053055\n",
            "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 0.873274\n",
            "Train Epoch: 6 [46000/50000 (92%)]\tLoss: 0.844404\n",
            "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.208119\n",
            "\n",
            "Test set: Average loss: 0.7546, Accuracy: 7936/10000 (79.4%)\n",
            "\n",
            "Best Accuracy   78.98\n",
            "Train Epoch: 7 [    0/50000 (0%)]\tLoss: 0.153926\n",
            "Train Epoch: 7 [ 2000/50000 (4%)]\tLoss: 0.013221\n",
            "Train Epoch: 7 [ 4000/50000 (8%)]\tLoss: 0.146240\n",
            "Train Epoch: 7 [ 6000/50000 (12%)]\tLoss: 0.002870\n",
            "Train Epoch: 7 [ 8000/50000 (16%)]\tLoss: 0.054718\n",
            "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 2.267171\n",
            "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 0.015660\n",
            "Train Epoch: 7 [14000/50000 (28%)]\tLoss: 0.000079\n",
            "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.725446\n",
            "Train Epoch: 7 [18000/50000 (36%)]\tLoss: 0.251816\n",
            "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 0.514264\n",
            "Train Epoch: 7 [22000/50000 (44%)]\tLoss: 0.746034\n",
            "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 0.013991\n",
            "Train Epoch: 7 [26000/50000 (52%)]\tLoss: 0.463927\n",
            "Train Epoch: 7 [28000/50000 (56%)]\tLoss: 0.180105\n",
            "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 0.019255\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.593613\n",
            "Train Epoch: 7 [34000/50000 (68%)]\tLoss: 0.635010\n",
            "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 0.045421\n",
            "Train Epoch: 7 [38000/50000 (76%)]\tLoss: 0.011213\n",
            "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [42000/50000 (84%)]\tLoss: 0.000087\n",
            "Train Epoch: 7 [44000/50000 (88%)]\tLoss: 0.041336\n",
            "Train Epoch: 7 [46000/50000 (92%)]\tLoss: 0.000194\n",
            "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.024144\n",
            "\n",
            "Test set: Average loss: 0.7394, Accuracy: 8034/10000 (80.3%)\n",
            "\n",
            "Best Accuracy   79.36\n",
            "Train Epoch: 8 [    0/50000 (0%)]\tLoss: 0.000384\n",
            "Train Epoch: 8 [ 2000/50000 (4%)]\tLoss: 0.000002\n",
            "Train Epoch: 8 [ 4000/50000 (8%)]\tLoss: 0.002146\n",
            "Train Epoch: 8 [ 6000/50000 (12%)]\tLoss: 0.158878\n",
            "Train Epoch: 8 [ 8000/50000 (16%)]\tLoss: 0.000086\n",
            "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 0.575074\n",
            "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 0.495097\n",
            "Train Epoch: 8 [14000/50000 (28%)]\tLoss: 0.025992\n",
            "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.639849\n",
            "Train Epoch: 8 [18000/50000 (36%)]\tLoss: 0.008485\n",
            "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 0.003877\n",
            "Train Epoch: 8 [22000/50000 (44%)]\tLoss: 0.000063\n",
            "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 0.023631\n",
            "Train Epoch: 8 [26000/50000 (52%)]\tLoss: 0.450795\n",
            "Train Epoch: 8 [28000/50000 (56%)]\tLoss: 0.000575\n",
            "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 0.000017\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.325705\n",
            "Train Epoch: 8 [34000/50000 (68%)]\tLoss: 0.002741\n",
            "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 0.034929\n",
            "Train Epoch: 8 [38000/50000 (76%)]\tLoss: 0.607512\n",
            "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 0.101833\n",
            "Train Epoch: 8 [42000/50000 (84%)]\tLoss: 0.000065\n",
            "Train Epoch: 8 [44000/50000 (88%)]\tLoss: 0.000038\n",
            "Train Epoch: 8 [46000/50000 (92%)]\tLoss: 0.354072\n",
            "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.369658\n",
            "\n",
            "Test set: Average loss: 0.8402, Accuracy: 8032/10000 (80.3%)\n",
            "\n",
            "Best Accuracy   80.34\n",
            "Train Epoch: 9 [    0/50000 (0%)]\tLoss: 0.004730\n",
            "Train Epoch: 9 [ 2000/50000 (4%)]\tLoss: 0.021100\n",
            "Train Epoch: 9 [ 4000/50000 (8%)]\tLoss: 0.000109\n",
            "Train Epoch: 9 [ 6000/50000 (12%)]\tLoss: 0.293130\n",
            "Train Epoch: 9 [ 8000/50000 (16%)]\tLoss: 0.000011\n",
            "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 0.613109\n",
            "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 0.082132\n",
            "Train Epoch: 9 [14000/50000 (28%)]\tLoss: 0.636814\n",
            "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.000208\n",
            "Train Epoch: 9 [18000/50000 (36%)]\tLoss: 0.216697\n",
            "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 0.003446\n",
            "Train Epoch: 9 [22000/50000 (44%)]\tLoss: 0.003854\n",
            "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 0.019249\n",
            "Train Epoch: 9 [26000/50000 (52%)]\tLoss: 0.000231\n",
            "Train Epoch: 9 [28000/50000 (56%)]\tLoss: 0.002935\n",
            "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 0.003705\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.000000\n",
            "Train Epoch: 9 [34000/50000 (68%)]\tLoss: 0.142503\n",
            "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 0.061227\n",
            "Train Epoch: 9 [38000/50000 (76%)]\tLoss: 0.054496\n",
            "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 0.015446\n",
            "Train Epoch: 9 [42000/50000 (84%)]\tLoss: 0.000606\n",
            "Train Epoch: 9 [44000/50000 (88%)]\tLoss: 0.000151\n",
            "Train Epoch: 9 [46000/50000 (92%)]\tLoss: 0.427920\n",
            "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.755089\n",
            "\n",
            "Test set: Average loss: 0.8733, Accuracy: 8056/10000 (80.6%)\n",
            "\n",
            "Best Accuracy   80.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ggqwe6P5I8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3beddc9c-0ae7-476c-e8bf-6f40c179c2ba"
      },
      "source": [
        "for epoch in range(10, 14):\n",
        "    trn_loss = train(model, device, trainloader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, testloader)\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "    if epoch%3 == 0:\n",
        "        lr = lr*0.9\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "        torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")\n",
        "\n",
        "torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 10 [    0/50000 (0%)]\tLoss: 0.001299\n",
            "Train Epoch: 10 [ 2000/50000 (4%)]\tLoss: 0.041230\n",
            "Train Epoch: 10 [ 4000/50000 (8%)]\tLoss: 0.000844\n",
            "Train Epoch: 10 [ 6000/50000 (12%)]\tLoss: 0.001837\n",
            "Train Epoch: 10 [ 8000/50000 (16%)]\tLoss: 0.002409\n",
            "Train Epoch: 10 [10000/50000 (20%)]\tLoss: 0.008640\n",
            "Train Epoch: 10 [12000/50000 (24%)]\tLoss: 0.001177\n",
            "Train Epoch: 10 [14000/50000 (28%)]\tLoss: 0.001109\n",
            "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.007589\n",
            "Train Epoch: 10 [18000/50000 (36%)]\tLoss: 0.013393\n",
            "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 0.000233\n",
            "Train Epoch: 10 [22000/50000 (44%)]\tLoss: 0.001019\n",
            "Train Epoch: 10 [24000/50000 (48%)]\tLoss: 0.011783\n",
            "Train Epoch: 10 [26000/50000 (52%)]\tLoss: 0.022745\n",
            "Train Epoch: 10 [28000/50000 (56%)]\tLoss: 0.040905\n",
            "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 0.416853\n",
            "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.010702\n",
            "Train Epoch: 10 [34000/50000 (68%)]\tLoss: 0.000620\n",
            "Train Epoch: 10 [36000/50000 (72%)]\tLoss: 0.000009\n",
            "Train Epoch: 10 [38000/50000 (76%)]\tLoss: 0.000009\n",
            "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 0.003256\n",
            "Train Epoch: 10 [42000/50000 (84%)]\tLoss: 0.002177\n",
            "Train Epoch: 10 [44000/50000 (88%)]\tLoss: 0.002603\n",
            "Train Epoch: 10 [46000/50000 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.516780\n",
            "\n",
            "Test set: Average loss: 0.8970, Accuracy: 8201/10000 (82.0%)\n",
            "\n",
            "Best Accuracy   80.56\n",
            "Train Epoch: 11 [    0/50000 (0%)]\tLoss: 0.000996\n",
            "Train Epoch: 11 [ 2000/50000 (4%)]\tLoss: 0.001815\n",
            "Train Epoch: 11 [ 4000/50000 (8%)]\tLoss: 0.011353\n",
            "Train Epoch: 11 [ 6000/50000 (12%)]\tLoss: 0.006441\n",
            "Train Epoch: 11 [ 8000/50000 (16%)]\tLoss: 0.000019\n",
            "Train Epoch: 11 [10000/50000 (20%)]\tLoss: 0.002778\n",
            "Train Epoch: 11 [12000/50000 (24%)]\tLoss: 0.220022\n",
            "Train Epoch: 11 [14000/50000 (28%)]\tLoss: 0.013470\n",
            "Train Epoch: 11 [16000/50000 (32%)]\tLoss: 0.001312\n",
            "Train Epoch: 11 [18000/50000 (36%)]\tLoss: 0.031452\n",
            "Train Epoch: 11 [20000/50000 (40%)]\tLoss: 0.016908\n",
            "Train Epoch: 11 [22000/50000 (44%)]\tLoss: 0.018871\n",
            "Train Epoch: 11 [24000/50000 (48%)]\tLoss: 0.012956\n",
            "Train Epoch: 11 [26000/50000 (52%)]\tLoss: 0.000148\n",
            "Train Epoch: 11 [28000/50000 (56%)]\tLoss: 0.000027\n",
            "Train Epoch: 11 [30000/50000 (60%)]\tLoss: 0.006266\n",
            "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.043147\n",
            "Train Epoch: 11 [34000/50000 (68%)]\tLoss: 0.006943\n",
            "Train Epoch: 11 [36000/50000 (72%)]\tLoss: 0.000003\n",
            "Train Epoch: 11 [38000/50000 (76%)]\tLoss: 0.035238\n",
            "Train Epoch: 11 [40000/50000 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [42000/50000 (84%)]\tLoss: 0.183681\n",
            "Train Epoch: 11 [44000/50000 (88%)]\tLoss: 0.032529\n",
            "Train Epoch: 11 [46000/50000 (92%)]\tLoss: 0.001944\n",
            "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 0.000044\n",
            "\n",
            "Test set: Average loss: 0.9149, Accuracy: 8153/10000 (81.5%)\n",
            "\n",
            "Best Accuracy   82.01\n",
            "Train Epoch: 12 [    0/50000 (0%)]\tLoss: 0.001065\n",
            "Train Epoch: 12 [ 2000/50000 (4%)]\tLoss: 0.003988\n",
            "Train Epoch: 12 [ 4000/50000 (8%)]\tLoss: 0.000097\n",
            "Train Epoch: 12 [ 6000/50000 (12%)]\tLoss: 0.000010\n",
            "Train Epoch: 12 [ 8000/50000 (16%)]\tLoss: 0.077108\n",
            "Train Epoch: 12 [10000/50000 (20%)]\tLoss: 0.000062\n",
            "Train Epoch: 12 [12000/50000 (24%)]\tLoss: 0.011205\n",
            "Train Epoch: 12 [14000/50000 (28%)]\tLoss: 0.002716\n",
            "Train Epoch: 12 [16000/50000 (32%)]\tLoss: 0.000581\n",
            "Train Epoch: 12 [18000/50000 (36%)]\tLoss: 0.000081\n",
            "Train Epoch: 12 [20000/50000 (40%)]\tLoss: 0.000259\n",
            "Train Epoch: 12 [22000/50000 (44%)]\tLoss: 0.000050\n",
            "Train Epoch: 12 [24000/50000 (48%)]\tLoss: 0.000143\n",
            "Train Epoch: 12 [26000/50000 (52%)]\tLoss: 0.000006\n",
            "Train Epoch: 12 [28000/50000 (56%)]\tLoss: 0.000010\n",
            "Train Epoch: 12 [30000/50000 (60%)]\tLoss: 0.000039\n",
            "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.000910\n",
            "Train Epoch: 12 [34000/50000 (68%)]\tLoss: 0.018017\n",
            "Train Epoch: 12 [36000/50000 (72%)]\tLoss: 0.000002\n",
            "Train Epoch: 12 [38000/50000 (76%)]\tLoss: 0.000001\n",
            "Train Epoch: 12 [40000/50000 (80%)]\tLoss: 0.060344\n",
            "Train Epoch: 12 [42000/50000 (84%)]\tLoss: 0.000004\n",
            "Train Epoch: 12 [44000/50000 (88%)]\tLoss: 0.000368\n",
            "Train Epoch: 12 [46000/50000 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [48000/50000 (96%)]\tLoss: 0.008255\n",
            "\n",
            "Test set: Average loss: 0.9278, Accuracy: 8145/10000 (81.5%)\n",
            "\n",
            "Best Accuracy   82.01\n",
            "Train Epoch: 13 [    0/50000 (0%)]\tLoss: 0.000009\n",
            "Train Epoch: 13 [ 2000/50000 (4%)]\tLoss: 0.003370\n",
            "Train Epoch: 13 [ 4000/50000 (8%)]\tLoss: 0.000003\n",
            "Train Epoch: 13 [ 6000/50000 (12%)]\tLoss: 0.009939\n",
            "Train Epoch: 13 [ 8000/50000 (16%)]\tLoss: 0.000010\n",
            "Train Epoch: 13 [10000/50000 (20%)]\tLoss: 0.002533\n",
            "Train Epoch: 13 [12000/50000 (24%)]\tLoss: 0.000128\n",
            "Train Epoch: 13 [14000/50000 (28%)]\tLoss: 0.000476\n",
            "Train Epoch: 13 [16000/50000 (32%)]\tLoss: 0.000178\n",
            "Train Epoch: 13 [18000/50000 (36%)]\tLoss: 0.001458\n",
            "Train Epoch: 13 [20000/50000 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [22000/50000 (44%)]\tLoss: 0.000643\n",
            "Train Epoch: 13 [24000/50000 (48%)]\tLoss: 0.000010\n",
            "Train Epoch: 13 [26000/50000 (52%)]\tLoss: 0.000337\n",
            "Train Epoch: 13 [28000/50000 (56%)]\tLoss: 0.000014\n",
            "Train Epoch: 13 [30000/50000 (60%)]\tLoss: 0.006623\n",
            "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.004231\n",
            "Train Epoch: 13 [34000/50000 (68%)]\tLoss: 0.000039\n",
            "Train Epoch: 13 [36000/50000 (72%)]\tLoss: 0.013512\n",
            "Train Epoch: 13 [38000/50000 (76%)]\tLoss: 0.000008\n",
            "Train Epoch: 13 [40000/50000 (80%)]\tLoss: 0.000008\n",
            "Train Epoch: 13 [42000/50000 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [44000/50000 (88%)]\tLoss: 0.000594\n",
            "Train Epoch: 13 [46000/50000 (92%)]\tLoss: 0.006035\n",
            "Train Epoch: 13 [48000/50000 (96%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.9729, Accuracy: 8248/10000 (82.5%)\n",
            "\n",
            "Best Accuracy   82.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fabcgobDPT8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "18c1711d-9db4-4b4c-cd22-0d2d630a1824"
      },
      "source": [
        "for epoch in range(15, 18):\n",
        "    trn_loss = train(model, device, trainloader, optimizer, epoch,log_interval)\n",
        "    test_loss,accuracy = test(model, device, testloader)\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    train_losses.append(trn_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "    if epoch%3 == 0:\n",
        "        lr = lr*0.9\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "        torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")\n",
        "\n",
        "torch.save(best_model_wts, str(best_acc)+\"CIFAR_cnn.pt\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c86f66df4ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHkmh6ruRj-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(1000):\n",
        "            label = labels[i]\n",
        "            y_true.append(classes[labels[i]])\n",
        "            y_pred.append(classes[predicted[i]])\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "import sklearn.metrics as metr\n",
        "mtrx = metr.confusion_matrix(y_true, y_pred, labels=classes)\n",
        "print(\"Confusion matrix: \\n\", mtrx)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}