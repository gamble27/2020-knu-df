{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part_0_adv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "db4a3uxmX0pM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms, datasets, models\n",
        "import torchvision\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import requests\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),  # Image net standards\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
        "    ])\n",
        "valid_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYE8IngcjlqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\"\n",
        "file = requests.get(url)\n",
        "f = open('newfile.tar.gz', 'wb')\n",
        "f.write(file.content)\n",
        "f.close()\n",
        "tar = tarfile.open('newfile.tar.gz', \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "os.remove('newfile.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQrN77wqtVN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"  Set up data directories       \"\"\"\n",
        "os.mkdir(\"datadir\")\n",
        "os.mkdir(\"datadir/train\")\n",
        "os.mkdir(\"datadir/valid\")\n",
        "os.mkdir(\"datadir/test\")\n",
        "\n",
        "\n",
        "for file in os.listdir(\"101_ObjectCategories/BACKGROUND_Google\"):\n",
        "    os.remove(\"101_ObjectCategories/BACKGROUND_Google/\"+file)\n",
        "os.rmdir(\"101_ObjectCategories/BACKGROUND_Google\")\n",
        "\n",
        "for file in os.listdir(\"101_ObjectCategories/Faces_easy\"):\n",
        "    os.remove(\"101_ObjectCategories/Faces_easy/\"+file)\n",
        "os.rmdir(\"101_ObjectCategories/Faces_easy\")\n",
        "\n",
        "def copyfile(filename, fromdir, todir):\n",
        "    fromfullpath = os.path.join(fromdir, filename)\n",
        "    tofullpath = os.path.join(todir, filename)\n",
        "    fromfile = open(fromfullpath, \"rb\")\n",
        "    tofile = open(tofullpath, \"wb\")\n",
        "    cnt = fromfile.read()\n",
        "    tofile.write(cnt)\n",
        "    fromfile.close()\n",
        "    tofile.close()\n",
        "\n",
        "pic_dirs = os.listdir(\"101_ObjectCategories\")\n",
        "new_dirs = [\"datadir/train\", \"datadir/valid\", \"datadir/test\"]\n",
        "\n",
        "for pic_d in pic_dirs:\n",
        "\n",
        "    for d in new_dirs:\n",
        "        os.mkdir(d+\"/\"+pic_d)\n",
        "    cur_dir = \"101_ObjectCategories/\"+pic_d\n",
        "    files = os.listdir(cur_dir)\n",
        "\n",
        "    valid_pics = files[:len(files)//4]\n",
        "    test_pics = files[len(files)//4:len(files)//2]\n",
        "    train_pics = files[len(files)//2:]\n",
        "    \n",
        "    for p in valid_pics:\n",
        "        copyfile(p, cur_dir, os.path.join(\"datadir/valid\",pic_d))\n",
        "        os.remove(cur_dir+\"/\"+p)\n",
        "\n",
        "    for p in test_pics:\n",
        "        copyfile(p, cur_dir, os.path.join(\"datadir/test\",pic_d))\n",
        "        os.remove(cur_dir+\"/\"+p)\n",
        "\n",
        "    for p in train_pics:\n",
        "        copyfile(p, cur_dir, \"datadir/train/\"+pic_d)\n",
        "        os.remove(cur_dir+\"/\"+p)\n",
        "    \n",
        "    os.rmdir(cur_dir)\n",
        "\n",
        "os.rmdir(\"101_ObjectCategories\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x16RbFLvZ94M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "627180da-3efa-4040-893c-0e1300c2dc9f"
      },
      "source": [
        "traindir = \"datadir/train\"\n",
        "validdir = \"datadir/valid\"\n",
        "testdir = \"datadir/test\"\n",
        "batchS = 128\n",
        "# Datasets from folders\n",
        "train_data = datasets.ImageFolder(root=traindir, transform=train_transforms)\n",
        "valid_data = datasets.ImageFolder(root=validdir, transform=valid_transforms)\n",
        "test_data = datasets.ImageFolder(root=testdir, transform=valid_transforms)\n",
        "\n",
        "# Dataloader iterators, make sure to shuffle\n",
        "train_dataloader = DataLoader(train_data, batch_size=batchS, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=batchS, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batchS, shuffle=False)\n",
        "\n",
        "trainiter = iter(train_dataloader)\n",
        "features, labels = next(trainiter)\n",
        "features.shape, labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 3, 224, 224]), torch.Size([128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVZEWG73X0fg",
        "colab_type": "code",
        "outputId": "3d839313-814d-467c-8e51-1ebc64554cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze model weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "n_classes=101\n",
        "n_inputs = 4096\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "model.classifier"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:10<00:00, 52.5MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=101, bias=True)\n",
              "    (4): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRH5RapIdwfd",
        "colab_type": "code",
        "outputId": "a2e904b0-0157-4b8a-cc38-f78611c5adb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "135,335,333 total parameters.\n",
            "1,074,789 training parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryeEfHO2wg4v",
        "colab_type": "text"
      },
      "source": [
        "I don't know why I have more parameters. In the guide they had 135,335,076 total parameters and 1,074,532 training parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sohu1PeMeYiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "# Distribute across 2 gpus\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Zn1ZGAoB8a",
        "colab_type": "code",
        "outputId": "8b92a7a5-6ba5-4f16-b4b2-7dbb043c5259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "n_epochs = 10\n",
        "# Early stopping details\n",
        "n_epochs_stop = 5\n",
        "min_val_loss = np.Inf\n",
        "epochs_no_improve = 0\n",
        "os.mkdir(\"saved_model\")\n",
        "checkpoint_path = \"saved_model/the_model.pt\"\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    val_loss = 0\n",
        "\n",
        "    for data, targets in train_dataloader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        out = model(data)\n",
        "        # Calculate loss\n",
        "        loss = criterion(out, targets)\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "    for data, targets in valid_dataloader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device) \n",
        "        out = model(data)\n",
        "        loss = criterion(out, targets)\n",
        "        val_loss += loss\n",
        "\n",
        "    # Average validation loss\n",
        "    val_loss = val_loss / len(valid_dataloader)\n",
        "    print(\"epoch: {}   validation loss: {}\".format(epoch, val_loss))\n",
        "\n",
        "    # If the validation loss is at a minimum\n",
        "    if val_loss < min_val_loss:\n",
        "        torch.save(model, checkpoint_path)\n",
        "        epochs_no_improve = 0\n",
        "        min_val_loss = val_loss\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        # Check early stopping condition\n",
        "        if epochs_no_improve == n_epochs_stop:\n",
        "            print('Early stopping!')\n",
        "            # Load the best model\n",
        "            model = torch.load(checkpoint_path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0   validation loss: 1.8340507745742798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DataParallel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type VGG. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1   validation loss: 1.928882360458374\n",
            "epoch: 2   validation loss: 2.316047191619873\n",
            "epoch: 3   validation loss: 2.410613775253296\n",
            "epoch: 4   validation loss: 2.5781357288360596\n",
            "epoch: 5   validation loss: 2.3955328464508057\n",
            "Early stopping!\n",
            "epoch: 6   validation loss: 1.8338189125061035\n",
            "epoch: 7   validation loss: 1.8251739740371704\n",
            "epoch: 8   validation loss: 1.8295753002166748\n",
            "epoch: 9   validation loss: 1.8364481925964355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzO3QEL2podA",
        "colab_type": "code",
        "outputId": "96861c8d-c3bc-4f17-e80f-43a7cf6477ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "correct = 0\n",
        "topk_correct = 0\n",
        "all = 0\n",
        "model.eval()\n",
        "for data, targets in test_dataloader:\n",
        "    data, targets = data.to(device), targets.to(device)\n",
        "    log_ps = model(data)\n",
        "    # Convert to probabilities\n",
        "    ps = torch.exp(log_ps).detach()\n",
        "\n",
        "    top_5_ps, top_5_classes = ps.topk(5, dim=1)\n",
        "    for i in range(top_5_classes.shape[0]):\n",
        "        five_classes = top_5_classes[i].cpu().numpy()\n",
        "        the_target = targets[i].item()\n",
        "        fl = False\n",
        "        for cl in five_classes:\n",
        "            if the_target == cl:\n",
        "                fl = True\n",
        "                break\n",
        "        if fl:\n",
        "            topk_correct += 1\n",
        "    \n",
        "    pred = torch.max(ps, dim=1).indices\n",
        "    equals = pred==targets\n",
        "    correct +=  torch.sum(equals).cpu().item()\n",
        "    all += len(equals)\n",
        "    \n",
        "accuracy = correct / all\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Top 5 accuracy: \", topk_correct/all)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6637764932562621\n",
            "Top 5 accuracy:  0.8742774566473989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S03Y9WT63ODk",
        "colab_type": "text"
      },
      "source": [
        "I have much lower accuracy than they had in the guide:("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRZtx3Y5kPXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4610d0dc-5c31-44bc-c960-36e8be2a5fbf"
      },
      "source": [
        "class_correct = list(0. for i in range(100))\n",
        "class_total = list(0. for i in range(100))\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(images.shape[0]):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "            total += 1\n",
        "\n",
        "classes = np.arange(0, 100)\n",
        "for i in range(100):\n",
        "    print('Accuracy of class %2s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of class  0 : 99 %\n",
            "Accuracy of class  1 : 100 %\n",
            "Accuracy of class  2 : 100 %\n",
            "Accuracy of class  3 : 92 %\n",
            "Accuracy of class  4 : 98 %\n",
            "Accuracy of class  5 :  0 %\n",
            "Accuracy of class  6 :  0 %\n",
            "Accuracy of class  7 : 41 %\n",
            "Accuracy of class  8 : 64 %\n",
            "Accuracy of class  9 : 58 %\n",
            "Accuracy of class 10 : 25 %\n",
            "Accuracy of class 11 : 96 %\n",
            "Accuracy of class 12 :  0 %\n",
            "Accuracy of class 13 :  0 %\n",
            "Accuracy of class 14 :  0 %\n",
            "Accuracy of class 15 : 73 %\n",
            "Accuracy of class 16 : 92 %\n",
            "Accuracy of class 17 :  0 %\n",
            "Accuracy of class 18 : 100 %\n",
            "Accuracy of class 19 :  0 %\n",
            "Accuracy of class 20 : 33 %\n",
            "Accuracy of class 21 : 31 %\n",
            "Accuracy of class 22 : 74 %\n",
            "Accuracy of class 23 : 58 %\n",
            "Accuracy of class 24 : 64 %\n",
            "Accuracy of class 25 : 16 %\n",
            "Accuracy of class 26 :  0 %\n",
            "Accuracy of class 27 :  7 %\n",
            "Accuracy of class 28 :  7 %\n",
            "Accuracy of class 29 : 85 %\n",
            "Accuracy of class 30 : 58 %\n",
            "Accuracy of class 31 : 76 %\n",
            "Accuracy of class 32 : 18 %\n",
            "Accuracy of class 33 : 41 %\n",
            "Accuracy of class 34 : 47 %\n",
            "Accuracy of class 35 : 87 %\n",
            "Accuracy of class 36 : 84 %\n",
            "Accuracy of class 37 : 100 %\n",
            "Accuracy of class 38 : 90 %\n",
            "Accuracy of class 39 : 76 %\n",
            "Accuracy of class 40 : 94 %\n",
            "Accuracy of class 41 : 27 %\n",
            "Accuracy of class 42 : 44 %\n",
            "Accuracy of class 43 : 100 %\n",
            "Accuracy of class 44 : 23 %\n",
            "Accuracy of class 45 : 100 %\n",
            "Accuracy of class 46 : 92 %\n",
            "Accuracy of class 47 : 45 %\n",
            "Accuracy of class 48 : 57 %\n",
            "Accuracy of class 49 :  4 %\n",
            "Accuracy of class 50 : 20 %\n",
            "Accuracy of class 51 : 25 %\n",
            "Accuracy of class 52 : 62 %\n",
            "Accuracy of class 53 : 81 %\n",
            "Accuracy of class 54 : 17 %\n",
            "Accuracy of class 55 : 93 %\n",
            "Accuracy of class 56 : 100 %\n",
            "Accuracy of class 57 : 70 %\n",
            "Accuracy of class 58 :  0 %\n",
            "Accuracy of class 59 : 41 %\n",
            "Accuracy of class 60 : 36 %\n",
            "Accuracy of class 61 :  0 %\n",
            "Accuracy of class 62 : 50 %\n",
            "Accuracy of class 63 :  0 %\n",
            "Accuracy of class 64 : 73 %\n",
            "Accuracy of class 65 : 42 %\n",
            "Accuracy of class 66 : 22 %\n",
            "Accuracy of class 67 : 70 %\n",
            "Accuracy of class 68 :  0 %\n",
            "Accuracy of class 69 : 70 %\n",
            "Accuracy of class 70 : 36 %\n",
            "Accuracy of class 71 : 92 %\n",
            "Accuracy of class 72 :  0 %\n",
            "Accuracy of class 73 : 21 %\n",
            "Accuracy of class 74 : 85 %\n",
            "Accuracy of class 75 : 53 %\n",
            "Accuracy of class 76 :  0 %\n",
            "Accuracy of class 77 : 50 %\n",
            "Accuracy of class 78 : 93 %\n",
            "Accuracy of class 79 :  0 %\n",
            "Accuracy of class 80 : 100 %\n",
            "Accuracy of class 81 :  0 %\n",
            "Accuracy of class 82 : 33 %\n",
            "Accuracy of class 83 : 81 %\n",
            "Accuracy of class 84 : 27 %\n",
            "Accuracy of class 85 : 86 %\n",
            "Accuracy of class 86 :  6 %\n",
            "Accuracy of class 87 : 87 %\n",
            "Accuracy of class 88 : 55 %\n",
            "Accuracy of class 89 : 85 %\n",
            "Accuracy of class 90 : 25 %\n",
            "Accuracy of class 91 : 95 %\n",
            "Accuracy of class 92 : 36 %\n",
            "Accuracy of class 93 : 91 %\n",
            "Accuracy of class 94 :  0 %\n",
            "Accuracy of class 95 : 13 %\n",
            "Accuracy of class 96 :  0 %\n",
            "Accuracy of class 97 : 92 %\n",
            "Accuracy of class 98 : 40 %\n",
            "Accuracy of class 99 : 73 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKnrFnUi27wK",
        "colab_type": "text"
      },
      "source": [
        "How to get class names? (to print: \"accuracy of crocodile\" instead of \"accuracy of class 56\")"
      ]
    }
  ]
}
